```commandline
- 웹 크롤링
    - 크롤링 :
    - 스크레핑 : 
    
    HTML 이해 - 웹 페이지를 만드는 언어
    태그 : 여닫는 꺽쇠괄호 안에 태그명을 사용
    
    속성 : 태그에 사용하는 것 
     ㄴ id : 페이지 안에서 다른 태그와 구분하기 위해서 태그에 id(시별자)를 부여해주는 속성
     ㄴ class : 태그들을 묶을 때 부여해주는 속성
     ㄴ id, class속성의 차이 : id속성의 값은 중복되면 안됨,
                             class속성의 값은 중복되도 됨
     ㄴ 태그 하나에 속성을 여러개 사용할 수 있음
     ㄴ 내가 원하는 속성도 그냥 만들어 넣어서 사용할수 있음                        
     
    브라우저의 개발자 도구 사용 방법
     ㄴ 요소 선택 툴 : 웹 페이지 내 컨텐츠를 선택하는 도구
     ㄴ 선텍자 복사 : copy selector 태그의 경로를 복사하는 메뉴 
     ㄴ 검색 : ctrl + f 검색 모드 활성화 후 검색
     
     
     
     
----------------------------------------------------------------------------
-memo-
라이브러리 설치 방법
  -> pip 프로그램을 사용해서 설치
  -> pip 프로그램은 명령을 사용해서 실행, 필요한 라이브러리를 설치

requests, BeautifulSoup 라이브러리
  ㄴ 개발이 오래 전에 완료된 프로젝트에서 사용
  ㄴ 간단하게 크롤링 테스트를 할 때 사용
 
셀리니움(Selenium) 라이브러리
  ㄴ 최근 개발 현장에서 사용되는 크롤링, 스크레핑 라이브러리

url의 구성요소
  ㄴ 프로토콜://서버의주소:포트번호
    https://search.naver.com/search.naver -> url
    ?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=코리아it학원 - > 파라미터
    파라미터1&파라미터2&...파라미터n
    파라미터는 -> 이름 = 값
  
응답과 관련된 응답코드
  ㄴ 200번대 -> 클라이언트의 요청에 문제가 없었고 요청한 서비스를 제대로 응답했다. 
  ㄴ 300번대 -> 클라이언트의 요청에 문제가 없었으나 요청한 서비스가 다른곳으로 이동했다.
  ㄴ 400번대 -> 클라이언트의 요청에 문제가 있어 요청한 서비르를 응답하지 못한다.
               파라미터(Parameter) : 서비스가 요청을 처리하기 위해 필요한 부가적인 데이터
  ㄴ 500번대 -> 클라이언트의 요청에 문제가 있는지 없는지 모르겠지만 서버에 문제가 생겨서 응답을 할수가 없다.
  
  웹 서비스를 요청했을 때 !항상! 응답코드(상태코드)를 먼저 확인해야함
  
requests(요청) 하는 방법
  1. requests 라이브러리 import
  2. requests.get(URL, PARAMETER)
  3. get 함수가 반환해주느 결과값을 변수에 저장
  4. 변수를 그대로 출력해서 응답코드를 확인
  5. text 멤버 변슈를 출력해서 결과값을 확인 또는 활용 
  
requests 한계
  ㄴ 컴퓨터가 요청을 하는것이기 때문에 반목문을 사용해서 쉽게 불필요한 요청을 굉장히 하도록 조작할수 있음
      그래서 서버 자체에서 requests로 한 요청은 응답하지 않도록 설정해둔 서버도 있음  
  ㄴ 필요한 데이터가 상대적이라거나 특정 시점의 데이터라면 못 할 수도 있음 
   
BeautifulSoup 함수
  find(찾고자하는 컨텐츠의 경로) : 찾고자 하는 컨텐츠 중 첫 번째 컨텐츠를 찾아주는 함수
  find_all(찾고자하는 컨텐츠의 경로) : 찾고자 하는 컨텐츠를 전부 찾아주는 함수
----------------------------------------------------------------
```